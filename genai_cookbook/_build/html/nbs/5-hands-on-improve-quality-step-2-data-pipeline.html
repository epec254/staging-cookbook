
<!DOCTYPE html>


<html lang="en" data-content_root="../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Implement data pipeline fixes &#8212; Databricks Generative AI Cookbook</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=3ee479438cf8b5e0d341" rel="stylesheet" />
<link href="../_static/styles/bootstrap.css?digest=3ee479438cf8b5e0d341" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=3ee479438cf8b5e0d341" rel="stylesheet" />

  
  <link href="../_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=3ee479438cf8b5e0d341" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=fa44fd50" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/sphinx-book-theme.css?v=384b581d" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css?v=be8a1c11" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-design.min.css?v=87e54e7c" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=3ee479438cf8b5e0d341" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=3ee479438cf8b5e0d341" />
  <script src="../_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=3ee479438cf8b5e0d341"></script>

    <script src="../_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="../_static/doctools.js?v=9a2dae69"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../_static/copybutton.js?v=f281be69"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?v=efea14e4"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../_static/design-tabs.js?v=f930bc37"></script>
    <script async="async" src="https://www.googletagmanager.com/gtag/js?id=G-6BZ4NTBHVJ"></script>
    <script>
                window.dataLayer = window.dataLayer || [];
                function gtag(){ dataLayer.push(arguments); }
                gtag('js', new Date());
                gtag('config', 'G-6BZ4NTBHVJ');
            </script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="../_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>
                window.dataLayer = window.dataLayer || [];
                function gtag(){ dataLayer.push(arguments); }
                gtag('js', new Date());
                gtag('config', 'G-6BZ4NTBHVJ');
            </script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'nbs/5-hands-on-improve-quality-step-2-data-pipeline';</script>
    <link rel="icon" href="../_static/favicon.ico"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Step 6: Deploy &amp; monitor" href="5-hands-on-deploy-and-monitor.html" />
    <link rel="prev" title="Step 6: Iteratively implement &amp; evaluate quality fixes" href="5-hands-on-improve-quality-step-2.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  

<a class="navbar-brand logo" href="../index.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../_static/logo2.png" class="logo__image only-light" alt="Databricks Generative AI Cookbook - Home"/>
    <script>document.write(`<img src="../_static/logo2.png" class="logo__image only-dark" alt="Databricks Generative AI Cookbook - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn navbar-btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Overview</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../index-2.html">Databricks Generative AI Cookbook</a></li>

</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Learn</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="1-introduction-to-rag.html">1. RAG overview</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="2-fundamentals-unstructured.html">2. RAG fundamentals</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="2-fundamentals-unstructured-data-pipeline.html">2.1. Data pipeline</a></li>
<li class="toctree-l2"><a class="reference internal" href="2-fundamentals-unstructured-chain.html">2.2. Retrieval, augmentation, and generation (aka RAG Chain)</a></li>
<li class="toctree-l2"><a class="reference internal" href="2-fundamentals-unstructured-eval.html">2.3. Evaluation &amp; monitoring</a></li>
<li class="toctree-l2"><a class="reference internal" href="2-fundamentals-unstructured-llmops.html">2.4. Governance and LLMops</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="3-deep-dive.html">3. RAG quality knobs</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="3-deep-dive-data-pipeline.html">3.1. Data pipeline</a></li>
<li class="toctree-l2"><a class="reference internal" href="3-deep-dive-chain.html">3.2. Retrieval, augmentation, and generation (aka RAG Chain)</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="4-evaluation.html">4. Evaluating RAG quality</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="4-evaluation-eval-sets.html">4.1. Defining “quality”: evaluation sets</a></li>
<li class="toctree-l2"><a class="reference internal" href="4-evaluation-metrics.html">4.2. Assessing performance: Metrics that Matter</a></li>
<li class="toctree-l2"><a class="reference internal" href="4-evaluation-infra.html">4.3. Enabling Measurement: Supporting Infrastructure</a></li>
</ul>
</details></li>
<li class="toctree-l1"><a class="reference internal" href="5-rag-development-workflow.html">5. Evaluation-driven development workflow</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Implement</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="5-hands-on-requirements.html"><strong>Prerequisite:</strong> Gather requirements</a></li>
<li class="toctree-l1"><a class="reference internal" href="6-implement-overview.html"><strong>Step 1:</strong> Clone code repo &amp; create compute</a></li>
<li class="toctree-l1"><a class="reference internal" href="5-hands-on-build-poc.html"><strong>Step 2:</strong> Deploy POC to collect stakeholder feedback</a></li>
<li class="toctree-l1"><a class="reference internal" href="5-hands-on-curate-eval-set.html"><strong>Step 3:</strong> Curate an Evaluation Set from stakeholder feedback</a></li>
<li class="toctree-l1"><a class="reference internal" href="5-hands-on-evaluate-poc.html"><strong>Step 4:</strong> Evaluate the POC’s quality</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="5-hands-on-improve-quality-step-1.html"><strong>Step 5:</strong> Identify the root cause of quality issues</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="5-hands-on-improve-quality-step-1-retrieval.html">Debugging retrieval quality</a></li>
<li class="toctree-l2"><a class="reference internal" href="5-hands-on-improve-quality-step-1-generation.html">Debugging generation quality</a></li>
</ul>
</details></li>
<li class="toctree-l1 current active has-children"><a class="reference internal" href="5-hands-on-improve-quality-step-2.html"><strong>Step 6:</strong> Iteratively implement &amp; evaluate quality fixes</a><details open="open"><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul class="current">
<li class="toctree-l2 current active"><a class="current reference internal" href="#"><strong></strong> Implement data pipeline fixes</a></li>
</ul>
</details></li>
<li class="toctree-l1"><a class="reference internal" href="5-hands-on-deploy-and-monitor.html"><strong>Step 6:</strong> Deploy &amp; monitor</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/databricks-genai-cookbook/cookbook" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/databricks-genai-cookbook/cookbook/issues/new?title=Issue%20on%20page%20%2Fnbs/5-hands-on-improve-quality-step-2-data-pipeline.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../_sources/nbs/5-hands-on-improve-quality-step-2-data-pipeline.md" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.md</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm navbar-btn theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch nav-link" data-mode="light"><i class="fa-solid fa-sun fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="dark"><i class="fa-solid fa-moon fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="auto"><i class="fa-solid fa-circle-half-stroke fa-lg"></i></span>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1> Implement data pipeline fixes</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#approach-1-implement-a-single-fix-at-a-time">Approach 1: Implement a single fix at a time</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#approach-2-implement-multiple-fix-at-once">Approach 2: Implement multiple fix at once</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#appendix">Appendix</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#configuration-settings-deep-dive">Configuration settings deep dive</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#implementing-a-custom-parser-chunker">Implementing a custom parser/chunker</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#add-a-new-parser">Add a new parser</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#add-a-new-chunker">Add a New Chunker</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#performance-tuning">Performance Tuning</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#running-the-pipeline-manually">Running the pipeline manually</a></li>
</ul>
</li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="implement-data-pipeline-fixes">
<h1><strong><img alt="Data pipeline" src="../_images/data_pipeline.png" /></strong> Implement data pipeline fixes<a class="headerlink" href="#implement-data-pipeline-fixes" title="Link to this heading">#</a></h1>
<p>Follow these steps to modify your data pipeline and run it to:</p>
<ol class="arabic simple">
<li><p>Create a new Vector Index</p></li>
<li><p>Create an MLflow Run with the data pipeline’s metadata</p></li>
</ol>
<p>The resulting MLflow Run will be reference by the <code class="docutils literal notranslate"><span class="pre">B_quality_iteration/02_evaluate_fixes</span></code> Notebook.</p>
<p>There are two approaches to modifying the data pipeline:</p>
<ol class="arabic simple">
<li><p><a class="reference internal" href="#approach-1-implement-a-single-fix-at-a-time"><span class="xref myst"><strong>Implement a single fix at a time:</strong></span></a> In this approach, you configure and run a single data pipeline at once.  This mode is best if you want to try a single embedding model, test out a single new parser, etc.  We suggest starting here to get familiar with these notebooks.</p></li>
<li><p><a class="reference internal" href="#approach-2-implement-multiple-fix-at-once"><span class="xref myst"><strong>Implement multiple fix at once:</strong></span></a> In this approach, also called a sweep, you, in parallel, run multiple data pipelines that each have a different configuration.  This mode is best if you want to “sweep” across many different strategies, for example, evaluate 3 PDF parsers or evaluate many different chunk sizes.</p></li>
</ol>
<section id="approach-1-implement-a-single-fix-at-a-time">
<h2>Approach 1: Implement a single fix at a time<a class="headerlink" href="#approach-1-implement-a-single-fix-at-a-time" title="Link to this heading">#</a></h2>
<ol class="arabic simple">
<li><p>Open the <code class="docutils literal notranslate"><span class="pre">B_quality_iteration/data_pipeline_fixes/single_fix/00_config</span></code> Notebook</p></li>
<li><p>Either:</p>
<ul class="simple">
<li><p>Follow the instructions there to implement a <a class="reference internal" href="#configuration-settings-deep-dive"><span class="xref myst">new configuration</span></a> provided by this Cookbook</p></li>
<li><p>Follow these <a class="reference internal" href="#implementing-a-custom-parserchunker"><span class="xref myst">steps</span></a> to implement custom code for a parsing or chunking.</p></li>
</ul>
</li>
<li><p>Run the pipeline, by either:</p>
<ul class="simple">
<li><p>Opening &amp; running the <a class="reference internal" href="#./00_Run_Entire_Pipeline"><span class="xref myst">00_Run_Entire_Pipeline</span></a> Notebook</p></li>
<li><p>Following these <a class="reference internal" href="#running-the-pipeline-manually"><span class="xref myst">steps</span></a> to run each step of the pipeline manually</p></li>
</ul>
</li>
<li><p>Add the name of the resulting MLflow Run that is outputted to the <code class="docutils literal notranslate"><span class="pre">DATA_PIPELINE_FIXES_RUN_NAMES</span></code> variable in <code class="docutils literal notranslate"><span class="pre">B_quality_iteration/02_evaluate_fixes</span></code> Notebook</p></li>
</ol>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The data preparation pipeline employs Spark Structured Streaming to incrementally load and process files. This entails that files already loaded and prepared are tracked in checkpoints and won’t be reprocessed. Only newly added files will be loaded, prepared, and appended to the corresponding tables.</p>
<p>Therefore, if you wish to <strong>rerun the entire pipeline from scratch</strong> and reprocess all documents, you need to delete the checkpoints and tables. You can accomplish this by using the <a class="reference internal" href="#./reset_tables_and_checkpoints.py"><span class="xref myst">reset_tables_and_checkpoints</span></a> notebook.</p>
</div>
</section>
<section id="approach-2-implement-multiple-fix-at-once">
<h2>Approach 2: Implement multiple fix at once<a class="headerlink" href="#approach-2-implement-multiple-fix-at-once" title="Link to this heading">#</a></h2>
<ol class="arabic simple">
<li><p>Open the <code class="docutils literal notranslate"><span class="pre">B_quality_iteration/data_pipeline_fixes/multiple_fixes/00_Run_Multiple_Pipelines</span></code> Notebook</p></li>
<li><p>Follow the instructions in the Notebook to add 2+ configurations of the data pipeline to run</p></li>
<li><p>Run the Notebook to execute these pipelines</p></li>
<li><p>Add the names of the resulting MLflow Runs that are outputted to the <code class="docutils literal notranslate"><span class="pre">DATA_PIPELINE_FIXES_RUN_NAMES</span></code> variable in <code class="docutils literal notranslate"><span class="pre">B_quality_iteration/02_evaluate_fixes</span></code> Notebook</p></li>
</ol>
</section>
<section id="appendix">
<h2>Appendix<a class="headerlink" href="#appendix" title="Link to this heading">#</a></h2>
<section id="configuration-settings-deep-dive">
<h3>Configuration settings deep dive<a class="headerlink" href="#configuration-settings-deep-dive" title="Link to this heading">#</a></h3>
<p>The various pre-implemented configuration options for the data pipeline are listed below.  Alternatively, you can implement a <a class="reference internal" href="#implementing-a-custom-parserchunker"><span class="xref myst">custom parser/chunker</span></a>.</p>
<ul>
<li><p><strong><code class="docutils literal notranslate"><span class="pre">vectorsearch_config</span></code></strong>: Specify the <a class="reference external" href="https://docs.databricks.com/en/generative-ai/vector-search.html">vector search</a> endpoint (must be up and running) and the name of the index to be created. Additionally, define the <a class="reference external" href="https://docs.databricks.com/en/generative-ai/create-query-vector-search.html#create-index-using-the-ui">synchronisation</a> type between the source table and the index (default is <code class="docutils literal notranslate"><span class="pre">TRIGGERED</span></code>).</p>
<ul>
<li><p><strong><code class="docutils literal notranslate"><span class="pre">embedding_config</span></code></strong>: Specify the embedding model to be used, along with the tokenizer. For a complete list of options see the <a class="reference internal" href="#./supporting_configs/embedding_models"><span class="xref myst"><code class="docutils literal notranslate"><span class="pre">supporting_configs/embedding_models</span></code></span></a> Notebook.  The embedding model has to be deployed to a running <a class="reference external" href="https://docs.databricks.com/en/generative-ai/create-query-vector-search">model serving endpoint</a>. Depending on chunking strategy, the tokenizer is also during splitting to make sure the chunks do not exceed the token limit of the embedding model.  Tokenizers are used here to count the number of tokens in the text chunks to ensure that they don’t exceed the maximum context length of the selected embedding model. Tokenizers from HuggingFace or TikToken can be selected, e.g.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span>    <span class="s2">&quot;embedding_tokenizer&quot;</span><span class="p">:</span> <span class="p">{</span>
        <span class="s2">&quot;tokenizer_model_name&quot;</span><span class="p">:</span> <span class="s2">&quot;BAAI/bge-large-en-v1.5&quot;</span><span class="p">,</span>
        <span class="s2">&quot;tokenizer_source&quot;</span><span class="p">:</span> <span class="s2">&quot;hugging_face&quot;</span><span class="p">,</span>
    <span class="p">}</span>
    <span class="err">```</span>

<span class="ow">or</span>

<span class="err">```</span><span class="n">Python</span>
<span class="s2">&quot;embedding_tokenizer&quot;</span><span class="p">:</span> <span class="p">{</span>
        <span class="s2">&quot;tokenizer_model_name&quot;</span><span class="p">:</span> <span class="s2">&quot;text-embedding-small&quot;</span><span class="p">,</span>
        <span class="s2">&quot;tokenizer_source&quot;</span><span class="p">:</span> <span class="s2">&quot;tiktoken&quot;</span><span class="p">,</span>
    <span class="p">}</span>
</pre></div>
</div>
</li>
<li><p><strong><code class="docutils literal notranslate"><span class="pre">pipeline_config</span></code></strong>: Defines the file parser, chunker and path to the sources field. Parsers and chunkers are defined in the <a class="reference internal" href="#./parser_library.py"><span class="xref myst">parser_library</span></a> and <a class="reference internal" href="#./chunker_library.py"><span class="xref myst">chunker_library</span></a> notebooks, respectively. For a complete list of options see the <a class="reference internal" href="#./supporting_configs/parser_chunker_strategies"><span class="xref myst"><code class="docutils literal notranslate"><span class="pre">supporting_configs/parser_chunker_strategies</span></code></span></a> Notebook.  Different parsers or chunkers may require different configuration parameters, e.g.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span>    <span class="s2">&quot;chunker&quot;</span><span class="p">:</span> <span class="p">{</span>
        <span class="s2">&quot;name&quot;</span><span class="p">:</span> <span class="o">&lt;</span><span class="n">chunker</span><span class="o">-</span><span class="n">name</span><span class="o">&gt;</span><span class="p">,</span>
        <span class="s2">&quot;config&quot;</span><span class="p">:</span> <span class="p">{</span>
            <span class="s2">&quot;&lt;param 1&gt;&quot;</span><span class="p">:</span> <span class="s2">&quot;...&quot;</span><span class="p">,</span>
            <span class="s2">&quot;&lt;param 2&gt;&quot;</span><span class="p">:</span> <span class="s2">&quot;...&quot;</span><span class="p">,</span>
            <span class="o">...</span>
        <span class="p">}</span>
    <span class="p">}</span>
</pre></div>
</div>
<p>where <code class="docutils literal notranslate"><span class="pre">&lt;param</span> <span class="pre">x&gt;</span></code> represent the potential parameters required for a specific chunker. Parsers can also be passed configuration values using the same format.</p>
</li>
</ul>
</li>
</ul>
</section>
<section id="implementing-a-custom-parser-chunker">
<h3>Implementing a custom parser/chunker<a class="headerlink" href="#implementing-a-custom-parser-chunker" title="Link to this heading">#</a></h3>
<p>This project is structured to facilitate the addition of custom parsers or chunkers to the data preparation pipeline.</p>
<section id="add-a-new-parser">
<h4>Add a new parser<a class="headerlink" href="#add-a-new-parser" title="Link to this heading">#</a></h4>
<p>Suppose you want to incorporate a new parser using the <a class="reference external" href="https://pypi.org/project/PyMuPDF/">PyMuPDF library</a> to transform parsed text into Markdown format. Follow these steps:</p>
<ol class="arabic">
<li><p>Install the required dependencies by adding the following code to the <a class="reference internal" href="#./parser_library.py"><span class="xref myst">parser_library notebook</span></a>:</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Dependencies for PyMuPdf</span>
<span class="o">%</span><span class="n">pip</span> <span class="n">install</span> <span class="n">pymupdf</span> <span class="n">pymupdf4llm</span>
</pre></div>
</div>
</li>
<li><p>In the <a class="reference internal" href="#./parser_library.py"><span class="xref myst">parser_library notebook</span></a>, add a new section for the <code class="docutils literal notranslate"><span class="pre">PyMuPdfMarkdown</span></code> parser and implement the parsing function:</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">fitz</span>
<span class="kn">import</span> <span class="nn">pymupdf4llm</span>

<span class="k">def</span> <span class="nf">parse_bytes_pymupdfmarkdown</span><span class="p">(</span>
    <span class="n">raw_doc_contents_bytes</span><span class="p">:</span> <span class="nb">bytes</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">ParserReturnValue</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="n">pdf_doc</span> <span class="o">=</span> <span class="n">fitz</span><span class="o">.</span><span class="n">Document</span><span class="p">(</span><span class="n">stream</span><span class="o">=</span><span class="n">raw_doc_contents_bytes</span><span class="p">,</span> <span class="n">filetype</span><span class="o">=</span><span class="s2">&quot;pdf&quot;</span><span class="p">)</span>
        <span class="n">md_text</span> <span class="o">=</span> <span class="n">pymupdf4llm</span><span class="o">.</span><span class="n">to_markdown</span><span class="p">(</span><span class="n">pdf_doc</span><span class="p">)</span>

        <span class="n">output</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s2">&quot;num_pages&quot;</span><span class="p">:</span> <span class="nb">str</span><span class="p">(</span><span class="n">pdf_doc</span><span class="o">.</span><span class="n">page_count</span><span class="p">),</span>
            <span class="s2">&quot;parsed_content&quot;</span><span class="p">:</span> <span class="n">md_text</span><span class="o">.</span><span class="n">strip</span><span class="p">(),</span>
        <span class="p">}</span>

        <span class="k">return</span> <span class="p">{</span>
            <span class="n">OUTPUT_FIELD_NAME</span><span class="p">:</span> <span class="n">output</span><span class="p">,</span>
            <span class="n">STATUS_FIELD_NAME</span><span class="p">:</span> <span class="s2">&quot;SUCCESS&quot;</span><span class="p">,</span>
        <span class="p">}</span>
    <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
        <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Exception </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2"> has been thrown during parsing&quot;</span><span class="p">)</span>
        <span class="k">return</span> <span class="p">{</span>
            <span class="n">OUTPUT_FIELD_NAME</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;num_pages&quot;</span><span class="p">:</span> <span class="s2">&quot;&quot;</span><span class="p">,</span> <span class="s2">&quot;parsed_content&quot;</span><span class="p">:</span> <span class="s2">&quot;&quot;</span><span class="p">},</span>
            <span class="n">STATUS_FIELD_NAME</span><span class="p">:</span> <span class="sa">f</span><span class="s2">&quot;ERROR: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span>
        <span class="p">}</span>
</pre></div>
</div>
<p>Ensure the output of the function complies with the <code class="docutils literal notranslate"><span class="pre">ParserReturnValue</span></code> class defined at the beginning of the notebook. This ensures compatibility with Spark UDFs. The <code class="docutils literal notranslate"><span class="pre">try</span></code>/<code class="docutils literal notranslate"><span class="pre">except</span></code> block prevents Spark from failing the entire parsing job due to errors in individual documents when applying the parser as a UDF in <a class="reference internal" href="#./02_parse_docs.py"><span class="xref myst">02_parse_docs</span></a>. This notebook will check if parsing failed for any document, quarantine the corresponding rows and raise a warning.</p>
</li>
<li><p>Add your new parsing function to the <code class="docutils literal notranslate"><span class="pre">parser_factory</span></code> in the <a class="reference internal" href="#./parser_library.py"><span class="xref myst">parser_library notebook</span></a> to make it configurable in the <code class="docutils literal notranslate"><span class="pre">pipeline_config</span></code> of the <a class="reference internal" href="#./00_config.py"><span class="xref myst">00_config notebook</span></a>.</p></li>
<li><p>In <a class="reference internal" href="#./02_parse_docs.py"><span class="xref myst">02_parse_docs</span></a>, parser functions are turned into Spark Python UDFs (<a class="reference external" href="https://www.databricks.com/blog/arrow-optimized-python-udfs-apache-sparktm-35">arrow-optimized</a> for DBR &gt;= 14.0) and applied to the dataframe containing the new binary PDF files. For testing and development, add a simple testing function to the <a class="reference internal" href="#./parser_library.py"><span class="xref myst">parser_library notebook</span></a> that loads the <a class="reference internal" href="#./test_data/test-document.pdf"><span class="xref myst">test-document.pdf</span></a> file and asserts successful parsing:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s2">&quot;./test_data/test-document.pdf&quot;</span><span class="p">,</span> <span class="s2">&quot;rb&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">file</span><span class="p">:</span>
    <span class="n">file_bytes</span> <span class="o">=</span> <span class="n">file</span><span class="o">.</span><span class="n">read</span><span class="p">()</span>
    <span class="n">test_result_pymupdfmarkdown</span> <span class="o">=</span> <span class="n">parse_bytes_pymupdfmarkdown</span><span class="p">(</span><span class="n">file_bytes</span><span class="p">)</span>

<span class="k">assert</span> <span class="n">test_result_pymupdfmarkdown</span><span class="p">[</span><span class="n">STATUS_FIELD_NAME</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;SUCCESS&quot;</span>
</pre></div>
</div>
</li>
</ol>
</section>
<section id="add-a-new-chunker">
<h4>Add a New Chunker<a class="headerlink" href="#add-a-new-chunker" title="Link to this heading">#</a></h4>
<p>The process for adding a new chunker follows similar steps to those explained above for a new parser.</p>
<ol class="arabic simple">
<li><p>Add the required dependencies in the <a class="reference internal" href="#./chunker_library.py"><span class="xref myst">chunker_library</span></a> notebook.</p></li>
<li><p>Add a new section for your chunker and implement a function, e.g., <code class="docutils literal notranslate"><span class="pre">chunk_parsed_content_newchunkername</span></code>. The output of the new chunker function must be a Python dictionary that complies with the <code class="docutils literal notranslate"><span class="pre">ChunkerReturnValue</span></code> class defined at the beginning of the <a class="reference internal" href="#./chunker_library.py"><span class="xref myst">chunker_library</span></a> notebook. The function should accept at least a string of the parsed text to be chunked. If your chunker requires additional parameters, you can add them as function parameters.</p></li>
<li><p>Add your new chunker to the <code class="docutils literal notranslate"><span class="pre">chunker_factory</span></code> function defined in the <a class="reference internal" href="#./chunker_library.py"><span class="xref myst">chunker_library</span></a> notebook. If your function accepts additional parameters, use <a class="reference external" href="https://docs.python.org/3/library/functools.html#functools.partial">functools’ partial</a> to pre-configure them. This is necessary because UDFs only accept one input parameter, which will be the parsed text in our case. The <code class="docutils literal notranslate"><span class="pre">chunker_factory</span></code> enables you to configure different chunker methods in the <a class="reference internal" href="#./00_config.py"><span class="xref myst">pipeline_config</span></a> and returns a Spark Python UDF (optimized for DBR &gt;= 14.0).</p></li>
<li><p>Add a simple testing section for your new chunking function. This section should chunk a predefined text provided as a string.</p></li>
</ol>
</section>
</section>
<section id="performance-tuning">
<h3>Performance Tuning<a class="headerlink" href="#performance-tuning" title="Link to this heading">#</a></h3>
<p>Spark utilizes partitions to parallelize processing. Data is divided into chunks of rows, and each partition is processed by a single core by default. However, when data is initially read by Apache Spark, it may not create partitions optimized for the desired computation, particularly for our UDFs performing parsing and chunking tasks. It’s crucial to strike a balance between creating partitions that are small enough for efficient parallelization and not so small that the overhead of managing them outweighs the benefits.</p>
<p>You can adjust the number of partitions using <code class="docutils literal notranslate"><span class="pre">df.repartitions(&lt;number</span> <span class="pre">of</span> <span class="pre">partitions&gt;)</span></code>. When applying UDFs, aim for a multiple of the number of cores available on the worker nodes. For instance, in the <a class="reference internal" href="#./02_parse_docs.py"><span class="xref myst">02_parse_docs</span></a> notebook, you could include <code class="docutils literal notranslate"><span class="pre">df_raw_bronze</span> <span class="pre">=</span> <span class="pre">df_raw_bronze.repartition(2*sc.defaultParallelism)</span></code> to create twice as many partitions as the number of available worker cores. Typically, a multiple between 1 and 3 should yield satisfactory performance.</p>
</section>
<section id="running-the-pipeline-manually">
<h3>Running the pipeline manually<a class="headerlink" href="#running-the-pipeline-manually" title="Link to this heading">#</a></h3>
<p>Alternatively, you can run each individual Notebook step-by-step:</p>
<ol class="arabic simple">
<li><p><strong>Load the raw files</strong> using the <a class="reference internal" href="#./01_load_files.py"><span class="xref myst">01_load_files</span></a> notebook. This saves each document binary as one record in a bronze table (<code class="docutils literal notranslate"><span class="pre">raw_files_table_name</span></code>) defined in the <code class="docutils literal notranslate"><span class="pre">destination_tables_config</span></code>. Files are loaded incrementally, processing only new documents since the last run.</p></li>
<li><p><strong>Parse the documents</strong> with the <a class="reference internal" href="#./02_parse_docs.py"><span class="xref myst">02_parse_docs</span></a> notebook. This notebook executes the <a class="reference internal" href="#./parser_library.py"><span class="xref myst">parser_library</span></a> notebook (<em>ensure to run this as the first cell to restart Python</em>), making different parsers and related utilities available. It then uses the specified parser in the <code class="docutils literal notranslate"><span class="pre">pipeline_config</span></code> to parse each document into plain text.</p></li>
</ol>
<blockquote>
<div><p>As an example, relevant metadata like the number of pages of the original PDF alongside the parsed text is captured. Successfully parsed documents are stored in a silver table (<code class="docutils literal notranslate"><span class="pre">parsed_docs_table_name</span></code>), while any unparsed documents are quarantined into a corresponding table.</p>
</div></blockquote>
<ol class="arabic simple" start="3">
<li><p><strong>Chunk the parsed documents</strong> using the <a class="reference internal" href="#./03_chunk_docs.py"><span class="xref myst">03_chunk_docs</span></a> notebook. Similar to parsing, this notebook executes the <a class="reference internal" href="#./chunker_library.py"><span class="xref myst">chunker_library</span></a> notebook (<em>again, run as the first cell</em>). It splits each parsed document into smaller chunks using the specified chunker from the <code class="docutils literal notranslate"><span class="pre">pipeline_config</span></code>. Each chunk is assigned a unique ID using an MD5 hash, necessary for synchronization with the vector search index. The final chunks are loaded into a gold table (<code class="docutils literal notranslate"><span class="pre">chunked_docs_table_name</span></code>).</p></li>
<li><p><strong>Create/Sync the vector search index</strong> with the <a class="reference internal" href="#./04_vector_index.py"><span class="xref myst">04_vector_index</span></a>. This notebook verifies the readiness of the specified vector search endpoint in the <code class="docutils literal notranslate"><span class="pre">vectorsearch_config</span></code>. If the configured index already exists, it initiates synchronization with the gold table; otherwise, it creates the index and triggers synchronization. This is expected to take some time if the Vector Search endpoint and index have not yet been created</p></li>
</ol>
</section>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./nbs"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="5-hands-on-improve-quality-step-2.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title"><strong>Step 6:</strong> Iteratively implement &amp; evaluate quality fixes</p>
      </div>
    </a>
    <a class="right-next"
       href="5-hands-on-deploy-and-monitor.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title"><strong>Step 6:</strong> Deploy &amp; monitor</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#approach-1-implement-a-single-fix-at-a-time">Approach 1: Implement a single fix at a time</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#approach-2-implement-multiple-fix-at-once">Approach 2: Implement multiple fix at once</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#appendix">Appendix</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#configuration-settings-deep-dive">Configuration settings deep dive</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#implementing-a-custom-parser-chunker">Implementing a custom parser/chunker</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#add-a-new-parser">Add a new parser</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#add-a-new-chunker">Add a New Chunker</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#performance-tuning">Performance Tuning</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#running-the-pipeline-manually">Running the pipeline manually</a></li>
</ul>
</li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By The Databricks GenAI Community
</p>

  </div>
  
  <div class="footer-item">
    

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/bootstrap.js?digest=3ee479438cf8b5e0d341"></script>
<script src="../_static/scripts/pydata-sphinx-theme.js?digest=3ee479438cf8b5e0d341"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>